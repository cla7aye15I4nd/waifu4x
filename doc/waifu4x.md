# waifu4x

## 这个项目是做什么的

​		计算机计算速度的不断提升，不仅体现在我们的CPU有了更高的性能，还体现在我们的内存容量更大访问更快，显示器的分辨率也不断提高。因此，我们对于图像分辨率的要求也更加苛刻。

​		而我们的项目的功能，就是将一张（或多张）分辨率较低的图像，通过一定的技术手段，生成一张分辨率高的图像。这就是图像超分辨率重建技术。我们有时候保存了有趣的图片/表情包，想要用的时候发现竟然保存的是低像素的版本，这时候我们的项目就能解决这个问题。

## 模糊的拟合-插值算法

我们用一个简单的例子来解释插值算法在图像超分辨率重建技术的应用，对于一张分辨率 3 x 2的图像，我们要把它变成 6 x 4的图像。

原图每个像素点的亮度值是：

![](./origin.jpg)

我们建立一个6 x 4的图像，把这6个已经知道的点，放在他们大概应该在新图的位置：

![](./middle.jpg)

我们如何知道蓝色部分的亮度值？我们自然的联想到多项式的插值算法，多项式的插值算法帮助我们能够从若干个离散的点还原出原多项式的形式, 然而多项式与图像的区别的在于我们是没有办法用一个特定形式的表达式去表示一个图像的。所以我们只能去尝试不同的表达，寻找合适的插值形式以求达到更好的效果。

​		基于插值的方法将每一张图像都看做是图像平面上的一个点，那么对超分辨率图像的估计可以看做是利用已知的像素信息为平面上未知的像素信息进行拟合的过程，这通常由一个预定义的变换函数或者插值核来完成。基于插值的方法计算简单、易于理解，但是也存在着一些明显的缺陷。

​		首先，它假设像素灰度值的变化是一个连续的、平滑的过程，但实际上这种假设并不完全成立。其次，在重建过程中，仅根据一个事先定义的转换函数来计算超分辨率图像，不考虑图像的降质退化模型，往往会导致复原出的图像出现模糊、锯齿等现象。常见的基于插值的方法包括最近邻插值法、双线性插值法和双立方插值法等。

## 深度学习方法

**深度学习**（英语：deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。

深度学习是机器学习中一种基于对数据进行表征学习的算法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。

![](1920px-Kernel_Machine.svg.png)

## 寻找图像特征-卷积

卷积数学中一种重要的运算。卷积也经常用在图像处理中。因为图像为一个两维结构，所以需要将
通常的一维卷积进行扩展。

给定一个图像$X \in \mathbb{R}^{M \times N}$, 和一个矩阵$W \in \mathbb{R}^{m\times n}$。卷积的定义为
$$
y_{ij}=\sum_{u=1}^m\sum_{v=1}^nw_{uv}\cdot x_{i-u+1,j-v+1}
$$
其中$W$被称为滤波器，也被称为卷积核。

这是卷积的一个实例：

![](./convex.png)
常用的均值滤波（mean filter）就是当前位置的像素值设为滤波器窗口中所有像素的平均值，也就是$f_{uv} =\frac 1 {mn}$。
在图像处理中，卷积经常作为特征提取的有效方法。一幅图像在经过卷积操作后得到结果称为特征映射（Feature Map）。

下图给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的高斯滤
波器，可以用来对图像进行平滑去噪；中间和最下面的过滤器可以用来提取边缘特征。

![](conv.png)

## 卷积神经网络

让计算机来处理图像，我自然希望计算机能识别出图像的特征。卷积网络（CNN）是一类尤其适合计算机视觉应用的神经网络，因为它们能使用局部操作对表征进行分层抽象。有两大关键的设计思想推动了卷积架构在计算机视觉领域的成功。

第一，CNN 利用了图像的 2D 结构，并且相邻区域内的像素通常是高度相关的。因此，CNN 就无需使用所有像素单元之间的一对一连接（大多数神经网络都会这么做），而可以使用分组的局部连接。

![](convlayer.png)

第二，CNN 架构依赖于特征共享，因此每个通道（即输出特征图）是在所有位置使用同一个过滤器进行卷积而生成的。

![](brain.png)


基于深度学习的图像超分辨率技术的重建流程主要包括以下几个步骤：

(1) 特征提取：首先对输入的低分辨率图像进行去噪、上采样等预处理，然后将处理后的图像送入神经网络，拟合图像中的非线性特征，提取代表图像细节的高频信息。

(2) 设计网络结构及损失函数：组合卷积神经网络及多个残差块，搭建网络模型，并根据先验知识设计损失函数；

(3) 训练模型：确定优化器及学习参数，使用反向传播算法更新网络参数，通过最小化损失函数提升模型的学习能力；’

(4) 验证模型：根据训练后的模型在验证集上的表现，对现有网络模型做出评估，并据此对模型做出相应的调整。

例如将卷积神经网络应用于超分辨率的开山之作, SRCNN首先使用双三次(bicubic)插值将低分辨率图像放大成目标尺寸，接着通过三层卷积网络拟合非线性映射，最后输出高分辨率图像结果。作者将三层卷积的结构解释成三个步骤：**图像块的提取和特征表示，特征非线性映射和最终的重建**。

![](./srcnn.png)


超分辨是将输入从low-resolution（LR）重建成high-resolution（HR）输出，SRCNN中分辨率的提升主要发生在第一层:通过双三次插值先把图像提升到目标大小。

而亚像素卷积层卷积层是另一种可以提升分辨率的层，它在效率和效果上都有很好的效果。
![](./sub-pixel-convolution.png)

## GAN

## 现在公开的情报
### 附加案例1
<img src="../readonly/example/sample.png" width="640px" />
<img src="../readonly/example/fakeHR.png" width="640px" /> 

### 附加案例2
<img src="../readonly/example/sample1.png" width="640px"/>
<img src="../readonly/example/fake1HR.png" width="640px" /> 

### 附加案例3
<img src="../readonly/example/sample2.png" width="640px" />
<img src="../readonly/example/fake2HR.png" width="640px" /> 

## Reference

